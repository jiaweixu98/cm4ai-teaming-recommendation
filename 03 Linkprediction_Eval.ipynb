{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare funcitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ntype_range(target_ntype):\n",
    "    start_idx = 0\n",
    "    for ntype in g[0].ntypes:\n",
    "        if ntype == target_ntype:\n",
    "            end_idx = start_idx + g[0].num_nodes(ntype)\n",
    "            return start_idx, end_idx\n",
    "        start_idx += g[0].num_nodes(ntype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics as Metric\n",
    "from sklearn.metrics import f1_score\n",
    "import torch as th\n",
    "\n",
    "def concat_u_v(x, u_idx, v_idx):\n",
    "    u = x[u_idx]\n",
    "    v = x[v_idx]\n",
    "    emd = th.cat((u, v), dim=1)\n",
    "    return emd\n",
    "\n",
    "def f1_node_classification(y_label, y_pred):\n",
    "    macro_f1 = f1_score(y_label, y_pred, average='macro')\n",
    "    micro_f1 = f1_score(y_label, y_pred, average='micro')\n",
    "    return macro_f1, micro_f1\n",
    "\n",
    "# Used in HetGNN\n",
    "def LR_pred(train_X, train_Y, test_X):\n",
    "    LR = LogisticRegression(max_iter=10000, random_state=0)\n",
    "    LR.fit(train_X, train_Y)\n",
    "    pred_Y = LR.predict(test_X)\n",
    "    # AUC_score = Metric.roc_auc_score(test_Y, pred_Y)\n",
    "    return pred_Y\n",
    "\n",
    "def link_prediction( train_X, train_Y, test_X, test_Y):\n",
    "    pred_Y = LR_pred(train_X, train_Y, test_X)\n",
    "    AUC_score = Metric.roc_auc_score(test_Y, pred_Y)\n",
    "    macro_f1, micro_f1 = f1_node_classification(test_Y, pred_Y)\n",
    "    return AUC_score, macro_f1, micro_f1\n",
    "\n",
    "def author_link_prediction(x, train_batch, test_batch):\n",
    "    train_u, train_v, train_Y = train_batch\n",
    "    test_u, test_v, test_Y = test_batch\n",
    "\n",
    "    train_X = concat_u_v(x, th.tensor(train_u), th.tensor(train_v))\n",
    "    test_X = concat_u_v(x, th.tensor(test_u), th.tensor(test_v))\n",
    "    train_Y = th.tensor(train_Y)\n",
    "    test_Y = th.tensor(test_Y)\n",
    "    return link_prediction(train_X, train_Y, test_X, test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# two year-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_link_pred(path):\n",
    "    u_list = []\n",
    "    v_list = []\n",
    "    label_list = []\n",
    "    with open(path) as f:\n",
    "        for i in f.readlines( ):\n",
    "            u, v, label = i.strip( ).split(', ')\n",
    "            u_list.append(int(u))\n",
    "            v_list.append(int(v))\n",
    "            label_list.append(int(label))\n",
    "    return u_list, v_list, label_list\n",
    "train_batch = load_link_pred('/data/jx4237data/TKG/new_TKG/TKG_new_BAI/630deliverable/OpenHGNN/openhgnn/dataset/academic4HetGNN/a_a_list_train_2015_modified.txt')\n",
    "test_batch = load_link_pred('/data/jx4237data/TKG/new_TKG/TKG_new_BAI/630deliverable/OpenHGNN/openhgnn/dataset/academic4HetGNN/a_a_list_test_2015_modified.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('/data/jx4237data/TKG/new_TKG/TKG_new_BAI/630deliverable/test/author_embeddings.pkl', 'rb') as f:\n",
    "    author_embeddings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.532143197162052, 0.5321131722163304, 0.5321431971620519)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Convert the tensor to a NumPy array\n",
    "author_embeddings_np = author_embeddings.numpy()\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=5)\n",
    "reduced_embeddings_np = pca.fit_transform(author_embeddings_np)\n",
    "\n",
    "# Convert back to a PyTorch tensor\n",
    "reduced_embeddings = torch.tensor(reduced_embeddings_np, dtype=torch.float32)\n",
    "author_link_prediction(reduced_embeddings, train_batch, test_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# metapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the .npy file\n",
    "embeddings = np.load('academic4HetGNN_APVPA_mp2vec_embeddings.npy')\n",
    "from dgl.data.utils import load_graphs\n",
    "g, _ = load_graphs('/data/jx4237data/TKG/new_TKG/TKG_new_BAI/630deliverable/OpenHGNN/openhgnn/dataset/academic4HetGNN/graph.bin')\n",
    "start_idx, end_idx = get_ntype_range('author')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "metaebd = th.tensor(embeddings[start_idx:end_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([35751, 128])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metaebd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5638765972771262, 0.5607311170696339, 0.5638765972771262)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Convert the tensor to a NumPy array\n",
    "metaebd_np = metaebd.numpy()\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=128)\n",
    "reduced_embeddings_np = pca.fit_transform(metaebd_np)\n",
    "\n",
    "# Convert back to a PyTorch tensor\n",
    "reduced_embeddings = torch.tensor(reduced_embeddings_np, dtype=torch.float32)\n",
    "author_link_prediction(reduced_embeddings, train_batch, test_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hetgnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "logits = torch.load('/data/jx4237data/TKG/new_TKG/TKG_new_BAI/630deliverable/OpenHGNN/openhgnn/output/HetGNN/embeddings.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5370473087924234, 0.5360103875918922, 0.5370473087924234)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Convert the tensor to a NumPy array\n",
    "logits_np = logits.numpy()\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=5)\n",
    "reduced_embeddings_np = pca.fit_transform(logits_np)\n",
    "\n",
    "# Convert back to a PyTorch tensor\n",
    "reduced_embeddings = torch.tensor(reduced_embeddings_np, dtype=torch.float32)\n",
    "author_link_prediction(reduced_embeddings, train_batch, test_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "HGT_logits = torch.load('/data/jx4237data/TKG/new_TKG/TKG_new_BAI/630deliverable/OpenHGNN/openhgnn/output/HGT/HGT_embeddings.pt',map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "HGT_logits['author'].shape\n",
    "import pickle\n",
    "new_tensor2oldtensor = pickle.load(open('/data/jx4237data/TKG/new_TKG/TKG_new_BAI/630deliverable/new_tensor2oldtensor.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reordered tensor shape: torch.Size([35751, 4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "original_tensor = HGT_logits['author']\n",
    "\n",
    "# Ensure the original tensor is on the same device as the new row tensor\n",
    "device = original_tensor.device  # Get the device of the original tensor\n",
    "\n",
    "# Create a new row tensor with the same number of columns (4) on the same device\n",
    "new_row = torch.zeros((1, 4), device=device)\n",
    "\n",
    "# Concatenate the new row to the original tensor\n",
    "updated_tensor = torch.cat((original_tensor, new_row), dim=0)\n",
    "\n",
    "# Assuming new_tensor2oldtensor is a dictionary mapping new indices to old indices\n",
    "# Ensure the index tensor is created on the same device\n",
    "index_tensor = torch.tensor([new_tensor2oldtensor[i] for i in range(35751)], device=device)\n",
    "\n",
    "# Reorder the updated tensor based on the index tensor\n",
    "reordered_tensor = updated_tensor[index_tensor]\n",
    "\n",
    "# Check the shape of the reordered tensor\n",
    "print(f\"Reordered tensor shape: {reordered_tensor.shape}\")\n",
    "\n",
    "# Update the HGT_logits dictionary with the reordered tensor\n",
    "HGT_logits['author'] = reordered_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.502896520036592, 0.49331052608409853, 0.502896520036592)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HGTLOGITS = HGT_logits['author'].cpu()  # Move the tensor to the CPU\n",
    "\n",
    "# Convert the tensor to a NumPy array\n",
    "HGTLOGITS_np = HGTLOGITS.numpy()\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA(n_components=4)\n",
    "reduced_embeddings_np = pca.fit_transform(HGTLOGITS_np)\n",
    "\n",
    "# Convert back to a PyTorch tensor\n",
    "reduced_embeddings = torch.tensor(reduced_embeddings_np, dtype=torch.float32)\n",
    "author_link_prediction(reduced_embeddings, train_batch, test_batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openhgnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
